[Presentation Video](https://youtu.be/C2ns5fGUxz8)

---

## Introduction

Hello, I am Chaesung Lim from WAKTAVERSE Games' backend team. In this post, I'd like to share the process of refactoring our long-standing task, the 'Google Spreadsheet Synchronization Method', and the performance improvement methods we applied.

## Role of WAKTAVERSE Games and Backend Team

First, I'll explain what kind of service WAKTAVERSE Games provides and the goals the development team aims to achieve. Our service is a fan game and application platform for the metaverse content WAKTAVERSE, created by the YouTuber WAKKOOD.

* Various features such as fan games, rankings, and challenges
* Consistency provided with DB using spreadsheets as admin pages
* 24-hour non-stop operation
* Statistics provided for rankings, downloads, and views in fan games & applications

Given these characteristics, our team can be considered a B2B and digital platform business team with a lot of paperwork and collaboration with partner teams (though technically, it's not a business as it's a non-commercial project).

## What is the Spreadsheet Data Synchronization Method?

In platform business, content is crucial. From the early stages of development, we used spreadsheets to collect content and develop services independently between teams, which allowed WAKTAVERSE Games to grow rapidly. Therefore, it can be considered a fundamental feature of WAKTAVERSE Games.
What does it mean to be fundamental to the service? It means it was developed before other features and is one of the oldest functions. WAKTAVERSE Games is now in its second year, and there are over 200 partner games. Traffic has increased significantly compared to the early days. With additional domains to manage and increased field numbers in sheets, we have reached a situation where this method needs refactoring for modifiability. Let's check the state of the data synchronization method.

### Problems with the Monster Method

The book "Working with Legacy Code" mentions the following:

> If large methods are hard to handle, monster methods can be called a disaster. A monster method is too long and complex, making you reluctant to touch it.

Over the two years WAKTAVERSE Games has been operating, this method has had numerous domains and complex conditions added, becoming an awful monster method. The state of the data synchronization method code was as follows:

* The code length exceeds 600 lines.
* There are no test codes, making modifications burdensome.
* Nobody fully understands the scope of the code's functionality.
* It is difficult to maintain as complex conditions keep getting added.

From the perspective of someone who has to modify it, it's a very burdensome and challenging method.
Let's call the method that synchronizes spreadsheet and DB information the "monster method."

## Refactoring

To refactor, you repeat a cycle of breaking down the functionality requirements in the following order.

1. Analyze
2. Write Test Code
3. Refactor

### Analyze

This is the most important part. You need to analyze how the method operates, where issues arise, whether the functionality belongs in this method, and if it's an intended existing code functionality or a bug. The important thing here is to analyze team members' codes, but not believe them blindly. Cultivate the habit of asking the coder about sections that seem likely to cause bugs in the code.

![](https://blog.kakaocdn.net/dn/67jYi/btsJDu49Q1E/GTTcdC4u1IqYQjbtbigWck/img.png)

The simple observation indicates that all of this processing is synchronized and blocking.

Seeing areas for improvement doesn't mean you can change the code immediately. Most of the time, the developer doing the refactoring does not know the history and impact of the code's function. What's needed here is **safe refactoring.**

### Write Test Code

Refactoring is about modifying the code structure without changing the function's result. However, refactoring is also not free from mistakes. When refactoring hundreds of lines of code, there can be many mistakes. Additionally, there's no documentation, making it unclear what functionality should operate within the code.
This is where test codes can be applied. Test codes prevent the following mistakes during refactoring:

Test codes are straightforward. They check whether the functionality operates as intended.

```js
test('Increases user age.', () => {
    let user = new User({age: 1});
    user.incrementAge();
    expect(user.age).toBe(2); // ✅ user.age == 2
})
```

This allows for continuous verification that refactoring has been correctly completed. But how many features need testing in hundreds of lines of code? It will be quite a lot. Especially for functions that communicate with DB, Redis, 3rd Party API, and more, testing can only become more complicated.
Therefore, the function must be divided into test-friendly code. There is a chart visualizing the test value/difficulty level of code needed.

![](https://blog.kakaocdn.net/dn/buZToX/btsJDnj0FIu/guwi2upy0Lf6v9ZMJGrttK/img.png)

Test Value/Difficulty Visualization

The code to be refactored currently belongs to 'complex code' with high test value/difficulty. To refactor this code, there is a need to isolate a lot of domain models, dependency objects into simpler codes. (Learn more: [Don't Write a Thousand Tests. Article 202](https://puleugo.tistory.com/202))

When writing test code for the first time, you may try to test private methods, but that's inappropriate. Consider adding a controllable area or splitting the function instead.

### Refactor

If separated well, the service layer becomes straightforward, and the complex parts of the business are assigned to the [domain model](https://puleugo.tistory.com/204).

```js
// Application Service: Example of Account Withdrawal
private TakeMoney(amount: number): void {
    if(!this.atm.canTakeMoney) { // Check if withdrawal is possible.
        throw AtmHasNotEnoughMoney('Withdrawal not possible');
    }
    const amountWithComission = this.atm.calculateAmountWithComission(amount); // Calculate amount including fees.
    this.paymentGateway.chargePayment(amountWithComission); // Charge amount.
    this.atm.takeMoney(amount); // Withdraw money.
    this.repository.save(this.atm); // Save changes.
}
```

In summary, roles are divided as follows:

* Domain Layer: All decision-makers
* Service Layer: Executor of domain layer's decisions

Let's carry out the refactoring.

## Applying Refactoring

### 1. Separate into Domain Models

I implemented a total of 3 domain models.

* Row: CSV 1ROW -> JSON, JSON -> DB QUERY, Validate, Numbering, etc.
* Rows: 1st-class collection of rows -> FILTERING, UPSERT, etc.
* SpreadSheet: FULL CSV ROW -> Rows Array (3D array)

![](https://blog.kakaocdn.net/dn/NALtZ/btsJERKLYl2/HnZqwhjB27MXitwoyW4YLk/img.png)

They can be used as follows:

```js
export interface SheetDto // Define DTO
{
    [SheetEnum.GAME]: Rows<GameRow>;
    [SheetEnum.APP]: Rows<AppRow>;
    // ...
}

// Get sheet data
function async getSheetData(sheetRange: Set<SheetEnum>): Promise<SheetDto> 
{
    const sheet = new SpreadSheet();
    
    // Return initial value if no sheet range requested
    if (sheetRange.size === 0)
        return sheet.values;

    const rawRows = await this.googleService.getRawSheet(this.sheetId, sheetRange); // Request raw values
    return sheet.fillRaws(rawRows).value; // Process and return raw values
}

// Use method
const {
    GAME: gameRows, // Game row data
    APP: appRows,   // Application row data
} = this.getSheetData(new Set([SheetEnum.ALL]));
console.log(typeof gameRows); // Rows<GameRow>
console.log(typeof appRows);  // Rows<AppRow>

gameRows.filterBy({edited: true}); // Filter edited data
gameRows.upsert(gameEntities); // Update or insert if data exists
this.googleService.updateSheet(gameRows); // Synchronize with Google Sheet
```

### 2. Separate Query Logic to Persistence Layer

An issue in the existing legacy code was writing queries in the business layer.

![](https://blog.kakaocdn.net/dn/bdsQE6/btsJDW0BQZ0/KB19it7q66yCKKqZNlHqe0/img.png)

Layered Architecture 4Layer

As shown in the following example, I moved queries to the persistence layer.

```js
class UserService {
    constructor(
        @InjectRepository(UserEntity)
        private readonly ormRepository: Repository<UserEntity>, // 1️⃣ Variable injected with the Repository instance created by the Framework
        @Inject(UserRepository)
        private readonly userRepository: UserRepository, // 2️⃣ Variable injected with the instance of UserRepository I registered
    ) {}

    addUserAge(userId: number) 
    {
        this.ormRepository.createQueryBuilder() // ❌ Use the persistence layer (UserRepository).
            .update().set({ age: () => 'age + 1' })
            .where({ id: userId })
            .excute();
    }
    
    refactoredAddUserAge(userId: number) 
    {
        this.userRepository.addUserAge(userId); // ✅ Let the persistence layer handle complex processes.
    }
}

@Injectable()
class UserRepository {
    constructor(
        @InjectRepository(UserEntity)
        private readonly ormUserRepository: Repository<UserEntity>,
    ) {}
    
    addUserAge(userId: number)
    {
        this.ormRepository.createQueryBuilder()
            .update().set({ age: 'age + 1' })
            .where({ id: userId })
            .excute();
    }
}
```

### Refactoring Results

#### Folder Structure

```
wt-games:
├─sheet
│ ├─sheet.module.ts
│ ├─sheet.controller.ts
│ ├─sheet.service.ts	# ⭐ 600 -> 200 lines
│ └─/domain			# ⭐ NEW
│   ├─spread-sheet.ts
│   ├─rows.ts
│   ├─row.ts
│   ├─game-row.ts
│   ├─application-row.ts
│   └─etc-row.ts
│
├─game
│ ├─game.module.ts
│ ├─game.service.ts		# 500 -> 300 lines
│ └─game.repository.ts	# ⭐ NEW
│
├─application
│ ├─application.module.ts
│ ├─application.service.ts		# 500 -> 300 lines
│ └─application.repository.ts	# ⭐ NEW
...
```

### Method Structure

```js
async private syncGame(gameRows: Rows<Game>): Promise<void>
{
    // 1️⃣ Synchronize with DB
    const deletedCount = await this.gameRepo.deleteExcludeBy({ids: gameRows.ids});
    // 2️⃣ Synchronize Spreadsheet data
    const editedGamesFromDb = await this.gameRepo.findEditedGames();
    gameRows.syncWithDbChanges(editedGamesFromDb);

    // 3️⃣ Reflect in DB
    const gameEntities = gameRows.toEntities;
    await this.gameRepo.upsertMany(gameEntities);

    // 4️⃣ Reflect in Spreadsheet
    const updatedGameRows = gameRows.updatedRows;
    const updatedRowInfos = updatedGameRows.toRowInfos;
    await this.googleService.updateGoogleDocument(this.sheetId, updatedRowInfos);
}
```

By doing so, even though the logic is complex, readability has improved considerably.

## Performance Improvement

### Excessive API Call

![](https://blog.kakaocdn.net/dn/upplN/btsJDzSjxjV/tlCY00CoGfNFQn8wJGxk20/img.png)

151 calls to obtain information on 151 videos

### BULK Processing

According to the YouTube API specification, only 50 video data can be queried at a time.

![](https://blog.kakaocdn.net/dn/lOBkj/btsJEDM0sey/6gUVw4DmU7QeGAyJOvikG0/img.png)

4 calls to obtain information on 151 videos

Let's do a simple calculation. This is not an actual performance and precise indicator but a theoretical one.

#### Assumptions

* Total number of videos to query: N = 1,000
* Number of videos queried per API call: 50
* Time spent per API call: 0.5 seconds (including round-trip network time and server response time)
* Cost per API call: $0.01/1000 calls (API pricing set as an example)

#### 1. Original Method (Querying 1 video per call)

* Number of API calls: N = 1,000
* Total time spent: 1,000 calls * 0.5s = 500 seconds
* Network cost: 1,000 calls * $0.01/1000 = $0.01

#### 2. Improved Method (Querying 50 videos per call)

* Number of API calls: ⌈ N/50 ⌉ = ⌈ 1,000/50 ⌉ = 20
* Total time spent: 20 calls * 0.5s = 10 seconds
* Network cost: 20 calls * $0.01/1000 = $0.0002

|||||
|:---:|:---:|:---:|:---:|
|**Item**|**Original Method**|**Improved Method**|**Improvement Rate**|
|API calls|1,000|20|98% reduction|
|Total time|500s|10s|98% reduction|
|Network cost|$0.01|$0.0002|98% reduction|

### Synchronous Bottleneck

![](https://blog.kakaocdn.net/dn/u1EKp/btsJDpJbvGd/wC3NGtKAInaz83KVUp3Fck/img.png)

### Asynchronous Processing

![](https://blog.kakaocdn.net/dn/cb0lkQ/btsJEovJLmU/ebb3UhCvQDzZEj79Wz5HcK/img.png)

When applying this method, understanding Node.js's operating principle is important. Node.js is characterized as single-threaded. You can achieve much faster execution results by actively using databases with non-blocking and asynchronous processing.

What's crucial is to provide a unique DB connection within Promise.all. If only one DB connection is used, Promise Pool waits until the function using that connection is complete, leading to sequential execution after all.

```js
async syncSheet()
{
    const 
    {
        GAME: gameRows,
        APP: appRows,
        GAME_GENRE: gameGenreRows,
        APP_GENRE: appGenreRows,
        ACHIEVE: achieveRows,
        BANNER: bannerRows,
        GUIDE: guideRows,
        BADGE: badgeRows,
    } = await this.getSheetData();
    
    await Promise.all
    ([
        syncGames(gameRows, gameGenreRows),
        syncApps(appRows, appGenreRows),
        syncAchieves(achieveRows),
        syncBanners(bannerRows),
        syncGuides(guideRows),
        syncBadges(badgeRows),
    ]);
    
    const images = [gameRows.allImageIds, appRows.allImageIds, achieveRows.allImageIds, bannerRows.allImageIds, badgeRows.allImageIds].flat();
    await this.s3Service.uploadFiles(images);
}
```

Related experiment article [Promise.all and Transactions (feat. Node.js)](https://jojoldu.tistory.com/639).

### Performance Improvement Result

The execution time result in an environment with better performance than the operating environment.

* Execution result: 3s → 2.7s
* About 10% speed improvement.