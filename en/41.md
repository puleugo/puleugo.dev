## Introduction

Recently, while discussing caching implementation methods with a club member, the topic of Redis came up, prompting me to organize my thoughts. The discussion revolved around the question, 'Is adopting Redis always the right answer?' My opinion was that **implementing Redis from the outset of service operations is not always the right answer, and it only makes sense when adopting MSA (Microservices Architecture) or operating services with multiple instances. For small services, using an application's dictionary data structure is also a good option.**

Both of us are hopeful job seekers, so we couldn't determine who was right on the spot. Thus, I wanted to investigate precisely what Redis truly is.

---

## What is Redis?

Simply put, it's a Cache Server. The name itself stands for *Remote Dictionary Server*. Often, people are encouraged to give Redis a try, but is there truly no alternative to Redis? Is Redis always the answer, as the title suggests?

Was there no service like Redis before 2011?
No, MemCached (from 2003) existed. Before MemCached, MySQL tables were sometimes used as caches. Due to limitations like the following, <u>Redis became mainstream</u>.

* **MemCached:** Lightweight but somewhat inadequate for large services.
  * **Value Max Size (1mb):** Not a drawback for lightweight uses.
  * **Lack of Replication Features.**
  * **Lack of Diverse Data Types.**
* **MySQL:** While easy to implement, it's slow and can cause significant troubleshooting issues as services grow.
  * **Scalability Issues:** Problems arise in horizontal scaling (distributed method).
  * **Slow Speed:**

When compared with Redis, these limitations appear. MySQL is not a practical choice realistically, but let's compare MemCached with dictionary data structures.

### Redis vs MemCached

Both are remote cache servers. Here's how they compare:

|   |   |   |
|---|---|---|
|**Criteria**|**Redis**|**MemCached**|
|**Design Philosophy**|<u>Data Store</u>, <u>Advanced Caching Solution</u>|Fast and <u>Simple Caching Solution</u>|
|**Speed**|Fast|Faster than Redis|
|**Data Structure Support**|Array, Set, Hash, Sorted Set, etc.|Key-Value Only|
|**Data Persistence**|File options available\- RDB (Redis Database File): Periodic Data Snapshots\- AOF (Append-Only File): Logs write operations to minimize potential data loss|Volatile Memory Only|
|**Memory Management**|Compression, [LRU](https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU), [TTL](https://en.wikipedia.org/wiki/Time_to_live)|LRU Only|
|**Scalability**|<u>Redis Cluster</u> support|\-|
|**Others**|Pub/Sub, Transaction, etc.|\-|

Indeed, these two choices are case by case.

**Choosing based on service scalability and data persistence requirements:**

* If you plan to use caching simply: &rarr; MemCached.
* If scalability, data persistence, and a distributed cache environment are needed: &rarr; Redis.

### MemCached vs Dictionary Data Structure

Let's compare them briefly.

|   |   |   |
|---|---|---|
|Criteria|MemCached|Dictionary|
|Data Sharing|Shared among multiple server instances|No cache sharing across multiple servers|
|Service Scale|Suitable for distributed servers and large-scale traffic|For single-server, small-scale applications|
|Speed|Possibility of network delays, but fast|No network delay, extremely fast with local memory|

**Choosing based on scalability needs:**

* If you need a simple local cache: &rarr; Dictionary.
* If data sharing and a distributed cache environment are needed: &rarr; MemCached.

---

## Conclusion

In summary, if you operate under the notion 'I have money to burn,' you can simply use Redis. This includes a perspective that considers cost-saving.

* **For multi-instance environments:**
  * When a distributed cache is needed: &rarr; Redis (Redis Cluster).
  * When a single cache suffices: &rarr; MemCached.
* **For single-instance environments:**
  * If a simple local cache is needed: &rarr; Cache library based on Dictionary.
* **When a server is unnecessary:**
  * Store caches on the client-side.